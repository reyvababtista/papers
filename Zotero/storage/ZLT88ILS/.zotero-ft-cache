
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2302.11154

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 22 Feb 2023 ( v1 ), last revised 24 Feb 2023 (this version, v2)]
Title: Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities
Authors: Hexiang Hu , Yi Luan , Yang Chen , Urvashi Khandelwal , Mandar Joshi , Kenton Lee , Kristina Toutanova , Ming-Wei Chang
Download a PDF of the paper titled Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities, by Hexiang Hu and 7 other authors
Download PDF

    Abstract: Large-scale multi-modal pre-training models such as CLIP and PaLI exhibit strong generalization on various visual domains and tasks. However, existing image classification benchmarks often evaluate recognition on a specific domain (e.g., outdoor images) or a specific task (e.g., classifying plant species), which falls short of evaluating whether pre-trained foundational models are universal visual recognizers. To address this, we formally present the task of Open-domain Visual Entity recognitioN (OVEN), where a model need to link an image onto a Wikipedia entity with respect to a text query. We construct OVEN-Wiki by re-purposing 14 existing datasets with all labels grounded onto one single label space: Wikipedia entities. OVEN challenges models to select among six million possible Wikipedia entities, making it a general visual recognition benchmark with the largest number of labels. Our study on state-of-the-art pre-trained models reveals large headroom in generalizing to the massive-scale label space. We show that a PaLI-based auto-regressive visual recognition model performs surprisingly well, even on Wikipedia entities that have never been seen during fine-tuning. We also find existing pretrained models yield different strengths: while PaLI-based models obtain higher overall performance, CLIP-based models are better at recognizing tail entities. 

Comments: 	Dataset available at this https URL
Subjects: 	Computer Vision and Pattern Recognition (cs.CV) ; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
Cite as: 	arXiv:2302.11154 [cs.CV]
  	(or arXiv:2302.11154v2 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2302.11154
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Hexiang Hu [ view email ]
[v1] Wed, 22 Feb 2023 05:31:26 UTC (5,961 KB)
[v2] Fri, 24 Feb 2023 00:50:25 UTC (5,961 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities, by Hexiang Hu and 7 other authors
    Download PDF
    PostScript
    Other Formats 

Current browse context:
cs.CV
< prev   |   next >
new | recent | 2302
Change to browse by:
cs
cs.AI
cs.CL
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

