
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2108.03353

Help | Advanced Search
Search
Computer Science > Human-Computer Interaction
(cs)
[Submitted on 7 Aug 2021]
Title: Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning
Authors: Bryan Wang , Gang Li , Xin Zhou , Zhourong Chen , Tovi Grossman , Yang Li
Download a PDF of the paper titled Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning, by Bryan Wang and 5 other authors
Download PDF

    Abstract: Mobile User Interface Summarization generates succinct language descriptions of mobile screens for conveying important contents and functionalities of the screen, which can be useful for many language-based application scenarios. We present Screen2Words, a novel screen summarization approach that automatically encapsulates essential information of a UI screen into a coherent language phrase. Summarizing mobile screens requires a holistic understanding of the multi-modal data of mobile UIs, including text, image, structures as well as UI semantics, motivating our multi-modal learning approach. We collected and analyzed a large-scale screen summarization dataset annotated by human workers. Our dataset contains more than 112k language summarization across âˆ¼ 22k unique UI screens. We then experimented with a set of deep models with different configurations. Our evaluation of these models with both automatic accuracy metrics and human rating shows that our approach can generate high-quality summaries for mobile screens. We demonstrate potential use cases of Screen2Words and open-source our dataset and model to lay the foundations for further bridging language and user interfaces. 

Comments: 	UIST'21
Subjects: 	Human-Computer Interaction (cs.HC) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
Cite as: 	arXiv:2108.03353 [cs.HC]
  	(or arXiv:2108.03353v1 [cs.HC] for this version)
  	https://doi.org/10.48550/arXiv.2108.03353
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Yang Li [ view email ]
[v1] Sat, 7 Aug 2021 03:01:23 UTC (43,119 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning, by Bryan Wang and 5 other authors
    Download PDF
    PostScript
    Other Formats 

Current browse context:
cs.HC
< prev   |   next >
new | recent | 2108
Change to browse by:
cs
cs.AI
cs.LG
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

DBLP - CS Bibliography
listing | bibtex
Bryan Wang
Gang Li
Xin Zhou
Zhourong Chen
Yang Li
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

