
Skip to main content
Cornell University
We gratefully acknowledge support from
the Simons Foundation, Columbia University , and all contributors. Donate
arxiv logo > cs > arXiv:2210.03350

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 7 Oct 2022 ( v1 ), last revised 17 Oct 2023 (this version, v3)]
Title: Measuring and Narrowing the Compositionality Gap in Language Models
Authors: Ofir Press , Muru Zhang , Sewon Min , Ludwig Schmidt , Noah A. Smith , Mike Lewis
Download a PDF of the paper titled Measuring and Narrowing the Compositionality Gap in Language Models, by Ofir Press and 5 other authors
Download PDF

    Abstract: We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning.
    We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy. 

Comments: 	To appear at Findings of EMNLP 2023
Subjects: 	Computation and Language (cs.CL)
Cite as: 	arXiv:2210.03350 [cs.CL]
  	(or arXiv:2210.03350v3 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2210.03350
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Ofir Press [ view email ]
[v1] Fri, 7 Oct 2022 06:50:23 UTC (1,367 KB)
[v2] Tue, 23 May 2023 00:57:12 UTC (1,387 KB)
[v3] Tue, 17 Oct 2023 18:57:17 UTC (1,371 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled Measuring and Narrowing the Compositionality Gap in Language Models, by Ofir Press and 5 other authors
    Download PDF
    Other Formats 

view license
Current browse context:
cs.CL
< prev   |   next >
new | recent | 2210
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

